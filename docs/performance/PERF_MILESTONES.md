# Performance Milestones (Triage → Targets → Work Items)

This document tracks the performance plan for `merman` with concrete, measurable milestones.
It is intentionally fixture-driven and stage-attributed (parse/layout/render/end-to-end).

## Current Status (2026-02-15)

### Stage Attribution Snapshot (canaries)

Stage spot-check (vs `repo-ref/mermaid-rs-renderer`) shows the remaining gap is *multi-source*:

- `render` is still behind on several diagram types (flowchart/class/mindmap/architecture),
- `layout` is the dominant gap for `mindmap` and `architecture`,
- `flowchart_medium` is still slower end-to-end mostly due to `layout` + `render`.

- Latest combined spotcheck report:
  - `docs/performance/spotcheck_2026-02-15.md` (`tools/bench/stage_spotcheck.py`, 10 samples / 1s warmup / 3s measurement)
  - Canary set (`flowchart_medium,class_medium,sequence_medium,mindmap_medium,architecture_medium`):
    - `parse` gmean: `1.39x`
    - `layout` gmean: `1.30x`
    - `render` gmean: `1.76x`
    - `end_to_end` gmean: `1.21x`
  - Notable outliers:
    - `architecture_medium`: `layout 6.19x`, `render 1.55x`, `end_to_end 3.12x` (absolute times are small; ratio is large)
    - `mindmap_medium`: `layout 3.45x`, `end_to_end 2.08x`
    - `class_medium`: `render 4.01x` (despite `end_to_end 0.53x`)
    - `flowchart_medium`: `render 1.77x`, `end_to_end 1.03x` (absolute times are ms-scale)

Near-term priorities (updated plan):

1. **Flowchart layout+render**: reduce `end_to_end/flowchart_medium` from `~1.0x` to `<= 1.0x` (and keep it there).
    This is a top priority because flowcharts tend to dominate absolute runtime (ms-scale).
2. **Mindmap layout**: reduce `layout/mindmap_medium` from `~4.1x` to `<= 2.0x` (COSE port / bbox).
3. **Architecture layout+render**: reduce fixed overhead on tiny diagrams and/or add a fast-path for
    common topologies to bring `end_to_end/architecture_medium` down from `~3.6x`.

Root-cause direction:

- `flowchart_medium` is now primarily a render problem:
  - flowchart parse now has a typed render-model fast path, and can be close to parity,
  - render has high fixed overhead from SVG emission (many small writes + style resolution),
  - layout is in the same ballpark but can still regress on `order` / `position_x`.
  - Latest canary numbers (spotcheck mid estimate): `parse 1.30x`, `layout 1.57x`, `render 1.90x`,
    `end_to_end 1.23x`.
  - After reusing layout-provided label metrics in the flowchart renderer (flowchart-only spotcheck,
    2026-02-14): `render 1.84x` (10 samples / 1s warmup / 4s measurement; spotcheck variance applies).
- BK x-positioning (`dugong::position::bk::position_x`) was a measurable secondary hotspot after
  ordering. We now reuse the already-computed `layering` matrix from the Dagre-ish pipeline and use
  `&str`-based temporary maps plus an index-based block-graph pass to reduce hashing + allocation.
  On this machine, `DUGONG_DAGREISH_TIMING=1` for `flowchart_medium` dropped `position_x` from
  ~`1.0ms` → ~`0.66ms` (single-run signal; spotcheck variance still applies).
- Compound border segments (`compound_border` / `add_border_segments`) had an accidental O(n^2)
  implementation detail: border dummy ids were generated by scanning `"_bl1"`, `"_bl2"`, ... from
  scratch for *every* new node. Switching to a per-prefix monotonic counter keeps naming identical
  but makes id allocation amortized O(1). On `flowchart_medium`, `compound_border` dropped from
  ~`0.8–0.9ms` to ~`0.28–0.35ms` in local `DUGONG_DAGREISH_TIMING=1` spot runs.
- The nesting graph pass (`nesting_run`) had the same O(n^2) dummy id scan pattern for `_root` /
  `_bt` / `_bb`. We applied the same monotonic id strategy to keep it from scaling badly on large
  compound graphs.
- Flowchart viewport work had some pure overhead: we were generating an edge path `d` string and
  then re-parsing it to approximate `getBBox()`. We now compute cubic bounds during curve emission
  for the viewBox approximation, avoiding `svg_path_bounds_from_d(...)` in the flowchart viewbox
  prepass (still builds the `d`, but no longer parses it).
- SVG emission still has measurable fixed overhead. Two recent low-risk wins:
  - Skip XML-escape scanning for `data-points` base64 payloads (and other known-safe path payloads).
  - Avoid repeated full-SVG rebuild passes for placeholder replacement:
    - patch initial `<svg ...>` attribute placeholders in-place when we can record their ranges (class),
    - otherwise do a single rebuild pass (state slow viewport finalize).
  - Avoid building the flowchart `<svg ...>` open tag via nested `format!(...)` + intermediate
    strings; write directly into the output buffer to reduce allocations.
- Flowchart edge path emission was allocating aggressively per edge (style joins + marker attribute
  formatting). We now write the style attribute and marker attrs directly into the output buffer to
  cut per-edge allocations (golden fixtures unchanged).
- Class diagram viewport work had the same pattern: we were accumulating `path_bounds` by parsing
  the emitted `d` strings. We now compute bounds during path emission for class edges + RoughJS-like
  strokes, and `path_bounds` micro-timing dropped from ~`O(50µs)` to ~`O(1–3µs)` for `class_medium`.
- `state_medium` render is dominated by leaf node work, especially RoughJS path generation and emit.
- `mindmap_medium` overall gap is now mostly layout (COSE port / bbox work) rather than parse.
- `architecture_medium` remaining gap is layout + SVG emission.
- Flowchart label metrics are now carried on `LayoutNode` for reuse in render, but are intentionally
  not serialized in layout golden snapshots (runtime-only fields).

Useful debug toggles:

- `MERMAN_RENDER_TIMING=1` (flowchart render stage attribution)
- `MERMAN_RENDER_TIMING=1` (mindmap + architecture coarse attribution)
- `MERMAN_PARSE_TIMING=1` (parse stage attribution: preprocess/detect/parse/sanitize)
- `MERMAN_FLOWCHART_LAYOUT_TIMING=1` (flowchart layout stage attribution)
- `MERMAN_MINDMAP_LAYOUT_TIMING=1` (mindmap layout coarse attribution: measure/manatee/edges/bounds)
- `MERMAN_ARCHITECTURE_LAYOUT_TIMING=1` (architecture layout coarse attribution: bfs/manatee/edges/bounds)
- `MANATEE_COSE_TIMING=1` (COSE-Bilkent internal breakdown: from_graph/flat_forest/radial/spring/transform/output)
- `DUGONG_DAGREISH_TIMING=1` (Dagre-ish pipeline stage attribution; shows `order` as dominant)
- `DUGONG_ORDER_TIMING=1` (ordering stage breakdown inside Dagre-ish pipeline)

### Class diagram (`class_medium`)

This fixture is useful as a counter-example:

- Spotcheck shows `layout` is already faster than `mmdr` (`~0.32x`), and end-to-end can be faster
  (`~0.48x` in the latest canary run), but `render` is still far behind (`~4x`).
- Implication: once we fix flowchart layout, **render optimizations will pay off across diagram
  types**, not only flowcharts.
- `MERMAN_RENDER_TIMING=1` now also emits a `[render-timing] diagram=classDiagram ...` line, so we
  can attribute class renderer hotspots without a profiler.

## Milestones

### M0 — Measurement is cheap (Done)

- Keep `tools/bench/stage_spotcheck.py` as the primary “did we move the right stage?” signal.
- Maintain per-diagram micro-timing toggles for fast attribution without a profiler.

### M1 — Flowchart render: avoid sanitizer for common labels (Done)

Goal: reduce `render/flowchart_medium` without changing SVG output.

Work items:

- Fast path for plain text labels in `flowchart_label_html(...)`.
- Skip icon regex expansion when the label cannot contain `:fa-...` syntax.

### M2 — Flowchart layout: make Dagre-ish ordering fast (In progress)

Goal: cut `layout/flowchart_medium` substantially.

Primary target: keep `layout/flowchart_medium` at `<= 1.0x` vs `mmdr` without changing layout output.
Current: `~1.34x` on `flowchart_medium` in the latest canary run (spotcheck variance applies).

What we know:

- `MERMAN_FLOWCHART_LAYOUT_TIMING=1` shows almost all layout time inside `dugong::layout_dagreish`.
- `DUGONG_DAGREISH_TIMING=1` shows the **`order`** phase dominates for `flowchart_medium`.
- `DUGONG_ORDER_TIMING=1` shows `sweeps` is the dominant sub-stage inside `order`.

Next work items (ordered by expected ROI):

1. Add micro-timing *inside* `sweeps` to identify the true dominant operations
   (e.g. barycenter evaluation vs conflict resolution vs sorting vs layer graph construction).
   (Done: `sort_subgraph_*` breakdown is now available in `[dugong-timing] stage=order ...`.)
2. Reduce allocations / cloning inside `sweeps` (reuse scratch buffers; avoid building temporary
   `Vec<String>` / `HashMap<String, ...>` where a borrowed view works).
   (In progress: `sort_subgraph(...)` now runs on node indices end-to-end (movable/barycenter/
   conflict-resolution/subgraph expansion/sort), and the order evaluator (`build_layer_matrix` +
   `cross_count`) is index-based as well. Remaining overhead is now dominated by layer-graph
   materialization + constraint-graph building.)
3. Reduce `build_layer_graph_cache` costs (this is outside `sweeps`, but still inside `order`):
   - Build cached layer graphs using a lightweight node label rather than cloning full `NodeLabel`.
   - Recent `DUGONG_ORDER_TIMING=1` single-run timings for `flowchart_medium` are in the
     `build_layer_graph_cache ~0.7ms` and `order total ~2.3ms` range (variance applies).
4. Deeper refactor (likely required): introduce an index-based internal representation for ordering
   sweeps:
   - map external `NodeKey` → dense `usize` once per `order(...)` call
   - represent adjacency as `Vec<Vec<usize>>` (or a flat CSR-style structure)
   - keep stable output by translating indices back to `NodeKey` at the boundary
   (Partially done: the sweep algorithm now works primarily on dense `usize` ids and only resolves
   back to node ids at the boundary when applying orders.)
5. Algorithmic improvement: early-exit sweeps when crossing count stops improving; avoid “fixed
   number of sweeps” when the order has converged.

Acceptance criteria:

- Spotcheck: `layout/flowchart_medium` stays at `<= 1.0x` and end-to-end drops proportionally.
- Layout micro-timing: `order` and especially `sweeps` drop materially (single-digit ms is a
  reasonable medium-term target for the medium fixture).

### M3 — State render: eliminate RoughJS cost (Partially done)

Goal: reduce `render/state_medium` without changing SVG output.

What we did:

- Cache RoughJS-generated path strings across render calls (global cache keyed by rough shape params),
  so Criterion iterations and server-style repeated renders avoid recomputing identical shapes.

Acceptance criteria:

- Spotcheck: `render/state_medium` drops materially and consistently, not only after warm caches.

Status note:

- The cache helps, but `state_medium` is still far behind in `render` stage ratios. The next steps
  are to reduce per-leaf overhead (style resolution, SVG emission) and increase cache hit rate for
  RoughJS shapes.

### M4 — Positioning: reduce `position_x` overhead (Done)

Goal: after `order` is no longer dominant, reduce the next hotspot(s) without changing layout.

Work items:

- Reduce repeated graph traversals and hashing in Brandes-Koepf positioning.
- Consider an index-based temporary representation for positioning (same strategy as ordering),
  if hashing dominates.

Acceptance criteria:

- `position_x` time drops in `DUGONG_DAGREISH_TIMING=1` output for `flowchart_medium`.

Status note:

- Landed: `position_x_with_layering(...)` fast path that:
  - reuses pipeline `layering` (no duplicate `build_layer_matrix`),
  - keeps conflicts/alignment maps keyed by `&str` (no per-iteration `String` cloning),
  - replaces the block-graph `Graph<(), f64, ()>` construction with an index-based edge list.

### M5 — Render: close the multi-diagram gap (In progress)

Goal: reduce `render/*` ratios (flowchart + class + state) while preserving SVG output.

Work items (expected ROI order):

- (Done) Avoid “build SVG path `d` → parse `d`” viewport bounds patterns by computing bounds during
  path generation (flowchart + class edges).
- (Done) Reduce SVG finalize fixed overhead:
  - skip XML-escape scanning for known-safe `data-points` base64 payloads
  - reduce placeholder replacement overhead (in-place patching for class; state fast viewport skips the pass)
- (Done) Avoid allocating temporary `String` for common attribute escaping (Display-based attr escape
  in flowchart tooltip emission).
- (Done) Reduce per-edge allocations in flowchart edge path emission (style attribute + marker attrs).
- (In progress) Avoid repeated `String` growth by pre-sizing buffers and using a single `String`
  builder per SVG (especially for flowchart node emission).
- (In progress) Reduce per-node overhead for the hot path:
  - avoid cloning the base `TextStyle` when a node has no class/style overrides
  - pre-parse class text overrides once per render call (so we don't re-split decl strings per node)
- (Done) Reduce HTML label style overhead by extracting `color/font-*` fields during style compilation
  (avoid rescanning `label_style` strings per node/edge label).
- (Done) Reuse flowchart node label metrics computed during layout (avoid re-measuring HTML/markdown
  labels during render).
- (Planned) Avoid cloning `effective_config` JSON in the hot render path; pass `MermaidConfig`
  (Arc-backed) through the render API so diagram renderers can read config without deep-cloning.
- (Planned) Cache per-diagram derived values that are reused many times (e.g. sanitized labels /
  class names), scoped to the render call to avoid cross-diagram leaks.

Acceptance criteria:

- Spotcheck: `render/flowchart_medium` and `render/class_medium` ratios drop materially without
  changing golden fixtures.

### M6 — Parser/IR: stop paying the `serde_json::Value` tax (In progress)

Motivation (from spotcheck):

- Many diagram pipelines pay a large allocation tax by constructing `serde_json::Value` object trees
  with repeated per-field key strings (e.g. `"id"`, `"label"`, `"shape"`) even when the downstream
  renderer only needs typed data.

Work items (ordered by expected ROI):

1. Add parse micro-timing (metadata detection vs preprocessing vs diagram parser vs JSON materialize).
2. Introduce typed parse paths for high-impact diagrams (start with `stateDiagram` and `mindmap`),
   and keep JSON emission as a compatibility layer (only when needed for debugging/tests). (Partially done)
   - `Engine::parse_diagram_for_render_model_sync(...)` returns typed semantic models for `mindmap`/`stateDiagram`.
   - The `parse/*` pipeline bench now measures the typed render parse path (so spotcheck ratios are apples-to-apples).
3. Stop cloning semantic JSON in layout/render decode paths (done for the main `merman-render`
   layout decoders via `T::deserialize(&Value)`).
4. Consider a lightweight lexer + hand-rolled parser for the hot subset where it measurably pays off.

Guidance:

- Do not switch to a parser combinator crate (e.g. `nom`) as a default move. That trade is mainly
  about maintainability and error reporting; it does not guarantee speed.

### M7 — Architecture: cut parse fixed-costs (Done)

Motivation (from spotcheck):

- `architecture_medium` was *dominated* by parse stage fixed costs (orders of magnitude vs `mmdr`),
  even on tiny inputs.

Work items (ordered by expected ROI):

1. Add a typed semantic model / typed render-model parse path for architecture (similar to flowchart). (Done)
2. Reduce preprocess overhead for short diagrams (avoid unnecessary allocations/scans). (Deferred; only if needed)
3. Audit the architecture parser for avoidable `String` cloning and map churn (prefer `&str`/interning). (Deferred; parse is no longer dominant)

Acceptance criteria:

- Spotcheck: `parse/architecture_medium` ratio drops by an order of magnitude without changing goldens.
  - Status: achieved (`parse` now < `1.0x` in local runs; layout/render remain behind).

## Fixture-driven Targets

We treat these fixtures as canaries:

- `flowchart_medium`: layout-heavy + many node labels.
- `state_medium`: render-heavy (shape generation / label handling).
- `class_medium`: end-to-end sanity (already close).
- `mindmap_medium`: layout-heavy (COSE port).
- `architecture_medium`: parse fixed-cost canary (tiny input).

When a milestone lands, record a new spotcheck report under `target/bench/` locally (do not commit)
and update this doc with the latest ratios.

## Non-goals (for now)

- “Switch graph crate” as a primary optimization strategy.
  - The dominant hotspots are algorithmic + representation issues in ordering/positioning; swapping
    a graph crate does not automatically remove the need for dense, index-based hot paths.
  - Prefer keeping the public graph API stable and introducing internal dense representations in
    performance-critical stages.
